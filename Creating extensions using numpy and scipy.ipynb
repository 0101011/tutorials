{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating extensions using numpy and scipy\n",
    "\n",
    "In this notebook, we shall go through two tasks:\n",
    "\n",
    "1. Create a neural network layer with no parameters. \n",
    "  - This calls into **numpy** as part of it's implementation\n",
    "2. Create a neural network layer that has learnable weights\n",
    "  - This calls into **SciPy** as part of it's implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Function\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter-less example\n",
    "\n",
    "This layer doesn't particularly do anything useful or mathematically correct.\n",
    "\n",
    "It is aptly named BadFFTFunction\n",
    "\n",
    "**Layer Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy.fft import rfft2, irfft2\n",
    "class BadFFTFunction(Function):\n",
    "    \n",
    "    def forward(self, input):\n",
    "        numpy_input = input.numpy()\n",
    "        result = abs(rfft2(numpy_input))\n",
    "        return torch.FloatTensor(result)\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        numpy_go = grad_output.numpy()\n",
    "        result = irfft2(numpy_go)\n",
    "        return torch.FloatTensor(result)\n",
    "\n",
    "# since this layer does not have any parameters, we can\n",
    "# simply declare this as a function, rather than as an nn.Module class\n",
    "def incorrect_fft(input):\n",
    "    return BadFFTFunction()(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example usage of the created layer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  4.8235   2.8210   4.0698  11.3034   4.0292\n",
      "  2.8678   6.5351   0.9228  15.3372   3.8725\n",
      "  4.0342   7.6988   3.8099   4.0796  12.9163\n",
      "  9.2561   6.0761   6.0133   5.7306   5.8949\n",
      "  6.1931   3.0239   8.3571   9.1645   2.3575\n",
      "  9.2561   7.6919   5.4074   9.5971   5.8949\n",
      "  4.0342  13.2063   9.0728   5.2962  12.9163\n",
      "  2.8678   2.4252   2.0834   4.9570   3.8725\n",
      "[torch.FloatTensor of size 8x5]\n",
      "\n",
      "\n",
      " 0.1849 -0.0055  0.0743 -0.0751  0.1089 -0.0751  0.0743 -0.0055\n",
      "-0.0662  0.1506  0.1307 -0.0629 -0.1199  0.0800 -0.0873  0.1036\n",
      "-0.0024 -0.0936  0.0083  0.0327 -0.1370 -0.2486 -0.0117 -0.0216\n",
      "-0.0074 -0.1277  0.0631  0.0348  0.0422  0.1335  0.0221 -0.0900\n",
      " 0.1353  0.0098  0.0030  0.0408 -0.0442  0.0408  0.0030  0.0098\n",
      "-0.0074 -0.0900  0.0221  0.1335  0.0422  0.0348  0.0631 -0.1277\n",
      "-0.0024 -0.0216 -0.0117 -0.2486 -0.1370  0.0327  0.0083 -0.0936\n",
      "-0.0662  0.1036 -0.0873  0.0800 -0.1199 -0.0629  0.1307  0.1506\n",
      "[torch.FloatTensor of size 8x8]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = Variable(torch.randn(8, 8), requires_grad=True)\n",
    "result = incorrect_fft(input)\n",
    "print(result.data)\n",
    "result.backward(torch.randn(result.size()))\n",
    "print(input.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametrized example\n",
    "\n",
    "This implements a layer with learnable weights.\n",
    "\n",
    "It implements the Cross-correlation with a learnable kernel.\n",
    "\n",
    "In deep learning literature, it's confusingly referred to as Convolution.\n",
    "\n",
    "The backward computes the gradients wrt the input and gradients wrt the filter.\n",
    "\n",
    "**Implementation:**\n",
    "\n",
    "*Please Note that the implementation serves as an illustration, and we did not verify it's correctness*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.signal import convolve2d, correlate2d\n",
    "from torch.nn.modules.module import Module\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "class ScipyConv2dFunction(Function):\n",
    "    \n",
    "    def forward(self, input, filter):\n",
    "        result = correlate2d(input.numpy(), filter.numpy(), mode='valid')\n",
    "        self.save_for_backward(input, filter)\n",
    "        return torch.FloatTensor(result)\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        input, filter = self.saved_tensors\n",
    "        grad_input = convolve2d(grad_output.numpy(), filter.t().numpy(), mode='full')\n",
    "        grad_filter = convolve2d(input.numpy(), grad_output.numpy(), mode='valid')\n",
    "        return torch.FloatTensor(grad_input), torch.FloatTensor(grad_filter)\n",
    "\n",
    "\n",
    "class ScipyConv2d(Module):\n",
    "    \n",
    "    def __init__(self, kh, kw):\n",
    "        super(ScipyConv2d, self).__init__()\n",
    "        self.filter=Parameter(torch.randn(kh, kw))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return ScipyConv2dFunction()(input, self.filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example usage: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "-0.1271  0.8109  0.4178\n",
      "-0.5126 -1.1835 -0.2776\n",
      " 0.4214  0.0886  1.0216\n",
      "[torch.FloatTensor of size 3x3]\n",
      "]\n",
      "Variable containing:\n",
      " 4.9120  0.6210  1.7908 -0.6933  3.4223  0.4025  2.0330  1.9110\n",
      "-1.6563 -0.9113 -2.3579  0.5714 -2.4509 -1.1477 -2.2362  0.2235\n",
      "-2.5879 -0.2629  0.0876  1.1707  1.2481  1.6186  1.2425  3.4960\n",
      " 2.6881  2.0360  1.5574 -0.8602 -2.8442 -2.2571 -1.5803 -2.0943\n",
      "-1.0176 -2.6565 -0.5091  1.5564  1.4575  3.1081  0.9570  1.0759\n",
      "-2.7108  0.7214 -3.5160 -2.0563  0.6138 -2.6700 -1.1769 -1.0721\n",
      " 2.8449  3.2918  1.6901  1.5427  2.4700  0.3433  2.2472  1.3501\n",
      "-3.9733 -1.4927 -0.6596 -1.2467 -2.1322  1.1351 -1.4640 -0.5982\n",
      "[torch.FloatTensor of size 8x8]\n",
      "\n",
      "\n",
      "-0.0466 -0.1651  0.2731  0.0436 -0.1487 -0.3089  0.7800  0.4718  0.1200 -0.5005\n",
      " 0.1600 -0.8988  1.6481  0.3330  0.3586 -2.7015  0.7774 -0.2702  1.4118  0.0614\n",
      " 1.1303 -2.6691  0.4635  1.2966  2.5482 -3.1470  2.8663 -1.8794 -1.9309 -0.8698\n",
      "-0.0614  1.5925 -0.7043 -0.9832 -0.7737 -4.6351  5.2933  0.2257 -0.9895  0.9198\n",
      "-0.9014  2.8442 -2.7092  2.2500  1.1892 -5.0975  2.4289  0.2922 -2.1747  0.8316\n",
      "-2.7050  3.6107 -1.7208 -0.4780 -0.3891 -2.2356  1.2152 -1.4541 -0.5707  1.2749\n",
      "-2.1614  2.0130 -4.0183  0.6822  0.9159  0.5670  3.7633 -0.9087  0.0326 -0.0958\n",
      " 0.3509  0.1484 -1.2759 -0.8248  0.8566 -2.6416  2.8875 -1.2788  1.1253  0.5939\n",
      "-0.0029  0.4912  1.8060 -1.4529  2.6439 -0.9157  0.5279 -3.4779  0.2804 -0.2260\n",
      "-0.1932  0.1283 -0.1745 -0.4872  1.0467 -0.1953  0.3003  1.3696  0.8338  0.4173\n",
      "[torch.FloatTensor of size 10x10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "module = ScipyConv2d(3, 3)\n",
    "print(list(module.parameters()))\n",
    "input = Variable(torch.randn(10, 10), requires_grad=True)\n",
    "output = module(input)\n",
    "print(output)\n",
    "output.backward(torch.randn(8, 8))\n",
    "print(input.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
